{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6df2cb",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "# ML for Healthcare with Weights & Biases: Interpretable Baselines and Clinical Evaluation\n",
    "\n",
    "We continue our focus on shifting from coding models to *understanding* them — how well they perform, how trustworthy their probabilities are, and how they behave across patient groups. Strenghtening the foundation for clinically aware ML practice.\n",
    "\n",
    "**Objective**  \n",
    "Build, track, and interpret models predicting in-hospital mortality in ICU patients using Weights & Biases (W&B).  \n",
    "This notebook transforms standard Machine Learning (ML) practice into an auditable, interpretable, and clinically meaningful workflow\n",
    "\n",
    "**You will learn**\n",
    "- How to track model training and evaluation runs using Weights & Biases  \n",
    "- How to interpret models and understand their calibration  \n",
    "- How to examine fairness and subgroup performance  \n",
    "- How to communicate model insights for healthcare decisions\n",
    "\n",
    "**Models**\n",
    "We’ll compare three interpretable baselines:\n",
    "1. **Logistic Regression**: simple linear reference, easy to explain  \n",
    "2. **Decision Tree (shallow)**: intuitive splits, visually transparent  \n",
    "3. **Random Forest**: robust ensemble, main focus for tuning and interpretability\n",
    "\n",
    "**Dataset**\n",
    "[PhysioNet Challenge 2012 dataset](https://physionet.org/content/challenge-2012/1.0.0/), containing clinical measurements, demographics, and the target:  \n",
    "`In-hospital_death` (binary: 1 = patient died during stay, 0 = survived).\n",
    "\n",
    "**Weights & Biases**\n",
    "Used to:\n",
    "- Track configurations, metrics, and plots  \n",
    "- Compare models and hyperparameters  \n",
    "- Log interpretability results (feature importance, calibration, subgroups)  \n",
    "- Support model transparency and documentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b201233",
   "metadata": {},
   "source": [
    "# 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ca632bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: imports, reproducibility, and Weights & Biases initialization\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "# Initialize Weights & Biases\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    average_precision_score, \n",
    "    brier_score_loss,\n",
    "    roc_curve, \n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d986fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wandb login\n",
    "# !wandb.login(relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4e94e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: idiazl to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\idiaz\\OneDrive - IE University\\00. IE Courses\\01. 2025_H2\\1. ML4HC\\ICU_Survival_analysis\\wandb\\run-20251022_195946-c3c37ya9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/c3c37ya9' target=\"_blank\">unique-pine-3</a></strong> to <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/c3c37ya9' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/c3c37ya9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights & Biases tracking URL: https://wandb.ai/idiazl/ml-healthcare-intro/runs/c3c37ya9\n"
     ]
    }
   ],
   "source": [
    "WB_PROJECT = \"ml-healthcare-intro\"\n",
    "\n",
    "# wandb.login() # Uncomment if not logged in\n",
    "run = wandb.init(\n",
    "    project=WB_PROJECT, \n",
    "    job_type=\"setup\", \n",
    "        config={\n",
    "        \"seed\": SEED,\n",
    "        \"framework\": \"scikit-learn\",\n",
    "        \"dataset\": \"physionet2012_set_a\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Log environment metadata\n",
    "wandb.config.update({\n",
    "    \"python_version\": sys.version.split()[0],\n",
    "    \"pandas_version\": pd.__version__,\n",
    "    \"numpy_version\": np.__version__,\n",
    "}, allow_val_change=True)\n",
    "\n",
    "print(f\"Weights & Biases tracking URL: {run.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ffd0e",
   "metadata": {},
   "source": [
    "# 3. Data loading and initial checks\n",
    "We will load the dataset, confirm the target, and log basic summaries to Weights & Biases. This lets us explore class balance, missingness, and a quick data preview directly in the dashboard.\n",
    "\n",
    "- Use the Weights & Biases tables to examine class balance, missingness, and a data preview  \n",
    "- Check that the target definition and event rate look reasonable before training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea8f066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ICU with shape (4000, 120) and positive rate 0.139\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "PATH = \"PhysionetChallenge2012-set-a.csv.gz\"\n",
    "\n",
    "# Simple check to ensure the data file exists before trying to load it\n",
    "if not os.path.exists(PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Error: The data file was not found at '{PATH}'. \"\n",
    "        \"Please ensure the dataset is in the correct directory.\"\n",
    "    )\n",
    "\n",
    "ICU = pd.read_csv(PATH, compression=\"gzip\")\n",
    "\n",
    "TARGET = \"In-hospital_death\"\n",
    "ID_COL = \"recordid\" if \"recordid\" in ICU.columns else None\n",
    "\n",
    "if TARGET not in ICU.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET}' not found in dataset\")\n",
    "\n",
    "# Ensure target is numeric and binary\n",
    "ICU[TARGET] = pd.to_numeric(ICU[TARGET], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Basic facts\n",
    "n_rows, n_cols = ICU.shape\n",
    "pos_rate = float(ICU[TARGET].mean())\n",
    "\n",
    "# Class balance table\n",
    "cb_series = ICU[TARGET].value_counts().sort_index()\n",
    "class_balance_tbl = wandb.Table(data=[[int(k), int(v), float(v / n_rows)] for k, v in cb_series.items()],\n",
    "                                columns=[\"label\", \"count\", \"fraction\"])\n",
    "\n",
    "# Missingness table (top 30)\n",
    "miss = ICU.isna().mean().sort_values(ascending=False)\n",
    "miss_top = miss.head(30).reset_index()\n",
    "miss_top.columns = [\"column\", \"missing_fraction\"]\n",
    "missing_tbl = wandb.Table(data=miss_top.values.tolist(), columns=list(miss_top.columns))\n",
    "\n",
    "# Data preview table (sample up to 200 rows for UI responsiveness)\n",
    "preview = ICU.sample(n=min(200, len(ICU)), random_state=SEED)\n",
    "preview_tbl = wandb.Table(dataframe=preview)\n",
    "\n",
    "wandb.log({\n",
    "    \"dataset_rows\": n_rows,\n",
    "    \"dataset_cols\": n_cols,\n",
    "    \"positive_rate\": pos_rate,\n",
    "    \"class_balance_table\": class_balance_tbl,\n",
    "    \"missingness_top30_table\": missing_tbl,\n",
    "    \"data_preview_table\": preview_tbl\n",
    "})\n",
    "\n",
    "print(f\"Loaded ICU with shape {ICU.shape} and positive rate {pos_rate:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e68fdbf",
   "metadata": {},
   "source": [
    "# 4. Simple preprocessing\n",
    "### Preprocessing and splits\n",
    "We will split the data into train, validation, and test sets, impute missing values and one-hot encode categorical variables, and log feature lists and split sizes to Weights & Biases for transparency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04bc083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2400, 118), Val: (800, 118), Test: (800, 118)\n",
      "Preprocessing complete\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: split data and prepare simple pipelines\n",
    "\n",
    "# Drop ID column if present\n",
    "X = ICU.drop(columns=[c for c in [TARGET, ID_COL] if c in ICU.columns])\n",
    "y = ICU[TARGET]\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# Split data (60 percent train, 20 percent validation, 20 percent test)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.25, stratify=y_train_full, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# Define transformations\n",
    "num_transformer = SimpleImputer(strategy=\"median\")\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, num_cols),\n",
    "        (\"cat\", cat_transformer, cat_cols)\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "preprocessor.set_output(transform=\"pandas\")\n",
    "\n",
    "# Fit and transform\n",
    "X_train_t = preprocessor.fit_transform(X_train)\n",
    "X_val_t = preprocessor.transform(X_val)\n",
    "X_test_t = preprocessor.transform(X_test)\n",
    "\n",
    "# Log split sizes\n",
    "wandb.log({\n",
    "    \"train_rows\": len(X_train),\n",
    "    \"val_rows\": len(X_val),\n",
    "    \"test_rows\": len(X_test),\n",
    "    \"n_num_features_raw\": len(num_cols),\n",
    "    \"n_cat_features_raw\": len(cat_cols),\n",
    "    \"n_features_transformed\": X_train_t.shape[1]\n",
    "})\n",
    "\n",
    "# Log feature lists as W&B Tables for inspectability\n",
    "num_tbl = wandb.Table(data=[[c, \"numeric\"] for c in num_cols], columns=[\"feature\", \"type\"])\n",
    "cat_tbl = wandb.Table(data=[[c, \"categorical\"] for c in cat_cols], columns=[\"feature\", \"type\"])\n",
    "wandb.log({\"feature_list_numeric\": num_tbl, \"feature_list_categorical\": cat_tbl})\n",
    "\n",
    "print(\"Preprocessing complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01940624",
   "metadata": {},
   "source": [
    "Use the feature tables and split sizes in Weights & Biases to verify preprocessing choices  \n",
    "All models next will consume the same transformed matrices for fair comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6087c95",
   "metadata": {},
   "source": [
    "# 5. Logistic Regression: establishing a simple reference\n",
    "\n",
    "Before exploring complex models, it’s helpful to start with a simple and interpretable baseline. Logistic Regression gives a linear relationship between features and the log-odds of the outcome. Helping us understand whether more flexible models (like Random Forests) truly add value.\n",
    "\n",
    "1. We’ll train a Logistic Regression model, evaluate it on the validation and test sets\n",
    "2. Log all metrics to Weights & Biases to compare later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8328bc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dataset_cols</td><td>▁</td></tr><tr><td>dataset_rows</td><td>▁</td></tr><tr><td>n_cat_features_raw</td><td>▁</td></tr><tr><td>n_features_transformed</td><td>▁</td></tr><tr><td>n_num_features_raw</td><td>▁</td></tr><tr><td>positive_rate</td><td>▁</td></tr><tr><td>test_rows</td><td>▁</td></tr><tr><td>train_rows</td><td>▁</td></tr><tr><td>val_rows</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dataset_cols</td><td>120</td></tr><tr><td>dataset_rows</td><td>4000</td></tr><tr><td>n_cat_features_raw</td><td>0</td></tr><tr><td>n_features_transformed</td><td>118</td></tr><tr><td>n_num_features_raw</td><td>118</td></tr><tr><td>positive_rate</td><td>0.1385</td></tr><tr><td>test_rows</td><td>800</td></tr><tr><td>train_rows</td><td>2400</td></tr><tr><td>val_rows</td><td>800</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-pine-3</strong> at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/c3c37ya9' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/c3c37ya9</a><br> View project at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a><br>Synced 5 W&B file(s), 5 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251022_195946-c3c37ya9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\idiaz\\OneDrive - IE University\\00. IE Courses\\01. 2025_H2\\1. ML4HC\\ICU_Survival_analysis\\wandb\\run-20251022_195957-d1sl0963</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/d1sl0963' target=\"_blank\">royal-pond-4</a></strong> to <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/d1sl0963' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/d1sl0963</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_brier</td><td>▁</td></tr><tr><td>test_pr</td><td>▁</td></tr><tr><td>val_auc</td><td>▁</td></tr><tr><td>val_brier</td><td>▁</td></tr><tr><td>val_pr</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auc</td><td>0.8622</td></tr><tr><td>test_brier</td><td>0.09375</td></tr><tr><td>test_pr</td><td>0.4755</td></tr><tr><td>val_auc</td><td>0.87606</td></tr><tr><td>val_brier</td><td>0.08569</td></tr><tr><td>val_pr</td><td>0.55215</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-pond-4</strong> at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/d1sl0963' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/d1sl0963</a><br> View project at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a><br>Synced 5 W&B file(s), 4 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251022_195957-d1sl0963\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR validation AUROC 0.876, AUPRC 0.552, Brier 0.086\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression baseline with ROC/PR logged as W&B Tables\n",
    "run = wandb.init(\n",
    "    project=WB_PROJECT,\n",
    "    job_type=\"baseline\",\n",
    "    config={\"model\": \"logistic_regression\", \"seed\": SEED},\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"thread\")\n",
    ")\n",
    "\n",
    "# Train\n",
    "log_reg = LogisticRegression(max_iter=500, solver=\"liblinear\", random_state=SEED)\n",
    "log_reg.fit(X_train_t, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_val_prob = log_reg.predict_proba(X_val_t)[:, 1]\n",
    "y_test_prob = log_reg.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "val_auc = roc_auc_score(y_val, y_val_prob)\n",
    "val_pr  = average_precision_score(y_val, y_val_prob)\n",
    "val_brier = brier_score_loss(y_val, y_val_prob)\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "test_pr  = average_precision_score(y_test, y_test_prob)\n",
    "test_brier = brier_score_loss(y_test, y_test_prob)\n",
    "\n",
    "wandb.log({\n",
    "    \"val_auc\": val_auc,\n",
    "    \"val_pr\": val_pr,\n",
    "    \"val_brier\": val_brier,\n",
    "    \"test_auc\": test_auc,\n",
    "    \"test_pr\": test_pr,\n",
    "    \"test_brier\": test_brier\n",
    "})\n",
    "\n",
    "# ROC and PR curve points as Tables for interactive plots in W&B\n",
    "fpr, tpr, roc_thresh = roc_curve(y_val, y_val_prob)\n",
    "roc_table = wandb.Table(data=list(zip(fpr, tpr, roc_thresh)), columns=[\"fpr\", \"tpr\", \"threshold\"])\n",
    "wandb.log({\"roc_curve_val\": roc_table})\n",
    "\n",
    "prec, rec, pr_thresh = precision_recall_curve(y_val, y_val_prob)\n",
    "# sklearn returns thresholds length one less than precision/recall, pad with None for table alignment\n",
    "pr_table = wandb.Table(data=list(zip(rec, prec, list(pr_thresh) + [None])), columns=[\"recall\", \"precision\", \"threshold\"])\n",
    "wandb.log({\"pr_curve_val\": pr_table})\n",
    "\n",
    "# Coefficients for transparency\n",
    "coef_df = pd.DataFrame({\"feature\": X_train_t.columns, \"coefficient\": log_reg.coef_[0]})\n",
    "coef_tbl = wandb.Table(dataframe=coef_df.sort_values(\"coefficient\", ascending=False))\n",
    "wandb.log({\"log_reg_coefficients\": coef_tbl})\n",
    "\n",
    "# Predictions table sample for later slicing in the UI\n",
    "pred_sample = pd.DataFrame({\n",
    "    \"id\": X_val.index if ID_COL is None else X_val.index,  # keep index for traceability\n",
    "    \"y_true\": y_val.values,\n",
    "    \"y_prob\": y_val_prob\n",
    "}).sample(n=min(500, len(y_val)), random_state=SEED)\n",
    "\n",
    "wandb.log({\"predictions_val_sample\": wandb.Table(dataframe=pred_sample)})\n",
    "\n",
    "run.finish()\n",
    "\n",
    "print(f\"LR validation AUROC {val_auc:.3f}, AUPRC {val_pr:.3f}, Brier {val_brier:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b057b",
   "metadata": {},
   "source": [
    "### To Do\n",
    "\n",
    "Open the Weights & Biases project  \n",
    "Use the ROC and PR tables to create interactive line plots for this run  \n",
    "Inspect the coefficients table for a first look at feature effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859adf44",
   "metadata": {},
   "source": [
    "# 6. Decision Tree baseline\n",
    "\n",
    "A shallow tree is easy to read and helps us see simple non-linear rules. We will train a small tree, log metrics, curve points, feature importances, and a predictions sample to Weights & Biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13c561d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\idiaz\\OneDrive - IE University\\00. IE Courses\\01. 2025_H2\\1. ML4HC\\ICU_Survival_analysis\\wandb\\run-20251022_200134-ebduz516</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/ebduz516' target=\"_blank\">honest-glade-5</a></strong> to <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/ebduz516' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/ebduz516</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_brier</td><td>▁</td></tr><tr><td>test_pr</td><td>▁</td></tr><tr><td>val_auc</td><td>▁</td></tr><tr><td>val_brier</td><td>▁</td></tr><tr><td>val_pr</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auc</td><td>0.99098</td></tr><tr><td>test_brier</td><td>0.01047</td></tr><tr><td>test_pr</td><td>0.94055</td></tr><tr><td>val_auc</td><td>0.98514</td></tr><tr><td>val_brier</td><td>0.01532</td></tr><tr><td>val_pr</td><td>0.9238</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-glade-5</strong> at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/ebduz516' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/ebduz516</a><br> View project at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a><br>Synced 5 W&B file(s), 4 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251022_200134-ebduz516\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT validation AUROC 0.985, AUPRC 0.924, Brier 0.015\n"
     ]
    }
   ],
   "source": [
    "# 6. Decision Tree baseline\n",
    "run = wandb.init(\n",
    "    project=WB_PROJECT,\n",
    "    job_type=\"baseline\",\n",
    "    config={\n",
    "        \"model_type\": \"decision_tree\",\n",
    "        \"seed\": SEED,\n",
    "        \"max_depth\": 4,\n",
    "        \"min_samples_leaf\": 20\n",
    "    },\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"thread\")\n",
    ")\n",
    "\n",
    "# Train a small, readable tree\n",
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=20,\n",
    "    random_state=SEED\n",
    ")\n",
    "dt.fit(X_train_t, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_val_prob = dt.predict_proba(X_val_t)[:, 1]\n",
    "y_test_prob = dt.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "val_auc = roc_auc_score(y_val, y_val_prob)                    # Area under ROC\n",
    "val_pr  = average_precision_score(y_val, y_val_prob)          # Area under PR\n",
    "val_brier = brier_score_loss(y_val, y_val_prob)               # Calibration error\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "test_pr  = average_precision_score(y_test, y_test_prob)\n",
    "test_brier = brier_score_loss(y_test, y_test_prob)\n",
    "\n",
    "wandb.log({\n",
    "    \"val_auc\": val_auc,\n",
    "    \"val_pr\": val_pr,\n",
    "    \"val_brier\": val_brier,\n",
    "    \"test_auc\": test_auc,\n",
    "    \"test_pr\": test_pr,\n",
    "    \"test_brier\": test_brier\n",
    "})\n",
    "\n",
    "# ROC and PR curve points as Tables\n",
    "fpr, tpr, roc_thresh = roc_curve(y_val, y_val_prob)\n",
    "wandb.log({\"roc_curve_val\": wandb.Table(data=list(zip(fpr, tpr, roc_thresh)), columns=[\"fpr\", \"tpr\", \"threshold\"])})\n",
    "\n",
    "prec, rec, pr_thresh = precision_recall_curve(y_val, y_val_prob)\n",
    "wandb.log({\"pr_curve_val\": wandb.Table(data=list(zip(rec, prec, list(pr_thresh) + [None])), columns=[\"recall\", \"precision\", \"threshold\"])})\n",
    "\n",
    "# Feature importances\n",
    "imp_df = (\n",
    "    pd.DataFrame({\"feature\": X_train_t.columns, \"importance\": dt.feature_importances_})\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "wandb.log({\"feature_importances\": wandb.Table(dataframe=imp_df)})\n",
    "\n",
    "# Predictions sample for slicing in the UI\n",
    "pred_sample = pd.DataFrame({\n",
    "    \"id\": X_val.index,\n",
    "    \"y_true\": y_val.values,\n",
    "    \"y_prob\": y_val_prob\n",
    "}).sample(n=min(500, len(y_val)), random_state=SEED)\n",
    "wandb.log({\"predictions_val_sample\": wandb.Table(dataframe=pred_sample)})\n",
    "\n",
    "run.finish()\n",
    "\n",
    "print(f\"DT validation AUROC {val_auc:.3f}, AUPRC {val_pr:.3f}, Brier {val_brier:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb201b",
   "metadata": {},
   "source": [
    "# 7. Random Forest baseline\n",
    "### Random Forest baseline\n",
    "\n",
    "As we know, a Random Forest averages many trees to improve stability and performance. We will train a baseline model and log metrics, curve points, feature importances, and a predictions sample to W&B. Later we will tune hyperparameters with a short sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd8e099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\idiaz\\OneDrive - IE University\\00. IE Courses\\01. 2025_H2\\1. ML4HC\\ICU_Survival_analysis\\wandb\\run-20251022_200552-y1aueqci</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/y1aueqci' target=\"_blank\">astral-pyramid-6</a></strong> to <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/y1aueqci' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/y1aueqci</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_brier</td><td>▁</td></tr><tr><td>test_pr</td><td>▁</td></tr><tr><td>val_auc</td><td>▁</td></tr><tr><td>val_brier</td><td>▁</td></tr><tr><td>val_pr</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auc</td><td>0.98419</td></tr><tr><td>test_brier</td><td>0.05763</td></tr><tr><td>test_pr</td><td>0.89292</td></tr><tr><td>val_auc</td><td>0.98135</td></tr><tr><td>val_brier</td><td>0.05921</td></tr><tr><td>val_pr</td><td>0.87774</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-pyramid-6</strong> at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/y1aueqci' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/y1aueqci</a><br> View project at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a><br>Synced 5 W&B file(s), 4 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251022_200552-y1aueqci\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF validation AUROC 0.981, AUPRC 0.878, Brier 0.059\n"
     ]
    }
   ],
   "source": [
    "# 7. Random Forest baseline\n",
    "run = wandb.init(\n",
    "    project=WB_PROJECT,\n",
    "    job_type=\"baseline\",\n",
    "    config={\n",
    "        \"model_type\": \"random_forest\",\n",
    "        \"seed\": SEED,\n",
    "        \"n_estimators\": 300,\n",
    "        \"max_depth\": None,\n",
    "        \"max_features\": \"sqrt\",\n",
    "        \"min_samples_leaf\": 5,\n",
    "        \"n_jobs\": -1\n",
    "    },\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"thread\")\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    max_features=\"sqrt\",\n",
    "    min_samples_leaf=5,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_t, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_val_prob = rf.predict_proba(X_val_t)[:, 1]\n",
    "y_test_prob = rf.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "val_auc = roc_auc_score(y_val, y_val_prob)                    # Area under ROC\n",
    "val_pr  = average_precision_score(y_val, y_val_prob)          # Area under PR\n",
    "val_brier = brier_score_loss(y_val, y_val_prob)               # Calibration error\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "test_pr  = average_precision_score(y_test, y_test_prob)\n",
    "test_brier = brier_score_loss(y_test, y_test_prob)\n",
    "\n",
    "wandb.log({\n",
    "    \"val_auc\": val_auc,\n",
    "    \"val_pr\": val_pr,\n",
    "    \"val_brier\": val_brier,\n",
    "    \"test_auc\": test_auc,\n",
    "    \"test_pr\": test_pr,\n",
    "    \"test_brier\": test_brier\n",
    "})\n",
    "\n",
    "# ROC and PR curve points as Tables\n",
    "fpr, tpr, roc_thresh = roc_curve(y_val, y_val_prob)\n",
    "wandb.log({\"roc_curve_val\": wandb.Table(data=list(zip(fpr, tpr, roc_thresh)), columns=[\"fpr\", \"tpr\", \"threshold\"])})\n",
    "\n",
    "prec, rec, pr_thresh = precision_recall_curve(y_val, y_val_prob)\n",
    "wandb.log({\"pr_curve_val\": wandb.Table(data=list(zip(rec, prec, list(pr_thresh) + [None])), columns=[\"recall\", \"precision\", \"threshold\"])})\n",
    "\n",
    "# Feature importances\n",
    "imp_df = (\n",
    "    pd.DataFrame({\"feature\": X_train_t.columns, \"importance\": rf.feature_importances_})\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "wandb.log({\"feature_importances\": wandb.Table(dataframe=imp_df)})\n",
    "\n",
    "# Predictions sample for slicing in the UI\n",
    "pred_sample = pd.DataFrame({\n",
    "    \"id\": X_val.index,\n",
    "    \"y_true\": y_val.values,\n",
    "    \"y_prob\": y_val_prob\n",
    "}).sample(n=min(500, len(y_val)), random_state=SEED)\n",
    "wandb.log({\"predictions_val_sample\": wandb.Table(dataframe=pred_sample)})\n",
    "\n",
    "run.finish()\n",
    "\n",
    "print(f\"RF validation AUROC {val_auc:.3f}, AUPRC {val_pr:.3f}, Brier {val_brier:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7f4af3",
   "metadata": {},
   "source": [
    "#### TO DO\n",
    "- Use the Weights & Biases compare view to contrast Logistic Regression, Decision Tree, and Random Forest  \n",
    "- Check whether the Random Forest improves area under ROC, area under PR, and calibration score  \n",
    "- Review feature importances to see if top drivers align with clinical sense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95542b",
   "metadata": {},
   "source": [
    "### 7.1. Calibration focus\n",
    "\n",
    "In clinical use, a calibrated model lets you set thresholds that align with safety targets. Let's log binned reliability tables and summary scores to Weights & Biases for Validation and Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c683f160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\idiaz\\OneDrive - IE University\\00. IE Courses\\01. 2025_H2\\1. ML4HC\\ICU_Survival_analysis\\wandb\\run-20251022_203903-vvoh8q3s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/vvoh8q3s' target=\"_blank\">glamorous-butterfly-8</a></strong> to <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/vvoh8q3s' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/vvoh8q3s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idiaz\\AppData\\Local\\Temp\\ipykernel_19324\\381828937.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  agg = dfb.groupby(\"bin\").agg(\n",
      "C:\\Users\\idiaz\\AppData\\Local\\Temp\\ipykernel_19324\\381828937.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  agg = dfb.groupby(\"bin\").agg(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_brier</td><td>▁</td></tr><tr><td>test_ece</td><td>▁</td></tr><tr><td>val_brier</td><td>▁</td></tr><tr><td>val_ece</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_brier</td><td>0.05763</td></tr><tr><td>test_ece</td><td>0.1074</td></tr><tr><td>val_brier</td><td>0.05921</td></tr><tr><td>val_ece</td><td>0.09969</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-butterfly-8</strong> at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/vvoh8q3s' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/vvoh8q3s</a><br> View project at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a><br>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251022_203903-vvoh8q3s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calibration for the current Random Forest baseline\n",
    "# Logs reliability tables and summary scores to Weights & Biases\n",
    "\n",
    "run = wandb.init(\n",
    "    project=WB_PROJECT,\n",
    "    job_type=\"calibration\",\n",
    "    config={\n",
    "        \"model_type\": \"random_forest\",\n",
    "        \"seed\": SEED,\n",
    "        \"calibration_bins\": 10,\n",
    "        \"calibration_splits\": [\"val\", \"test\"]\n",
    "    },\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"thread\")\n",
    ")\n",
    "\n",
    "\n",
    "# Helper to build a reliability table using equal-frequency bins\n",
    "def calibration_table(y_true, y_prob, n_bins=10):\n",
    "    # Rank-based bins for stable counts\n",
    "    q = pd.qcut(y_prob, q=n_bins, duplicates=\"drop\")\n",
    "    dfb = pd.DataFrame({\"y_true\": y_true, \"y_prob\": y_prob, \"bin\": q})\n",
    "    agg = dfb.groupby(\"bin\").agg(\n",
    "        mean_prob=(\"y_prob\", \"mean\"),\n",
    "        observed_rate=(\"y_true\", \"mean\"),\n",
    "        count=(\"y_true\", \"size\")\n",
    "    ).reset_index()\n",
    "    # expose numeric bin edges for plotting in W&B\n",
    "    agg[\"bin_low\"] = agg[\"bin\"].apply(lambda x: float(x.left))\n",
    "    agg[\"bin_high\"] = agg[\"bin\"].apply(lambda x: float(x.right))\n",
    "    agg = agg.drop(columns=[\"bin\"])\n",
    "    # Expected Calibration Error with equal-frequency bins\n",
    "    # Weighted by bin count over total\n",
    "    weights = agg[\"count\"] / agg[\"count\"].sum()\n",
    "    ece = float(np.sum(weights * np.abs(agg[\"observed_rate\"] - agg[\"mean_prob\"])))\n",
    "    return agg, ece\n",
    "\n",
    "# Build tables and summary scores\n",
    "cal_bins = 10\n",
    "cal_val_tbl, val_ece = calibration_table(y_val, y_val_prob, n_bins=cal_bins)\n",
    "cal_test_tbl, test_ece = calibration_table(y_test, y_test_prob, n_bins=cal_bins)\n",
    "\n",
    "val_brier = brier_score_loss(y_val, y_val_prob)\n",
    "test_brier = brier_score_loss(y_test, y_test_prob)\n",
    "\n",
    "# Log metrics\n",
    "wandb.log({\n",
    "    \"val_brier\": val_brier,\n",
    "    \"test_brier\": test_brier,\n",
    "    \"val_ece\": val_ece,\n",
    "    \"test_ece\": test_ece\n",
    "})\n",
    "\n",
    "# Log tables for interactive calibration plots in W&B\n",
    "wandb.log({\n",
    "    \"calibration_table_val\": wandb.Table(dataframe=cal_val_tbl),\n",
    "    \"calibration_table_test\": wandb.Table(dataframe=cal_test_tbl)\n",
    "})\n",
    "\n",
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3088e269",
   "metadata": {},
   "source": [
    "### To Do\n",
    "\n",
    "- Use the calibration tables in Weights & Biases to build line or bar charts  \n",
    "- Pay special attention to the high risk bins where clinical actions concentrate  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7a0c4",
   "metadata": {},
   "source": [
    "# 8. Threshold selection for clinical use\n",
    "- We'll choose operating thresholds on Validation to hit target sensitivity and specificity  \n",
    "- We'll freeze those thresholds and evaluate on Test  \n",
    "- Finally we'll log confusion matrices and clinical metrics to Weights & Biases for easy \n",
    "\n",
    "### Remember:\n",
    "- Pick thresholds on Validation to meet clinical goals, then freeze and report Test performance  \n",
    "- Sensitivity-first thresholds catch more true cases but raise alerts, specificity-first thresholds reduce false alarms  \n",
    "- Use the Weights & Biases tables to compare predictive values and confusion matrices for each operating point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5178856b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\idiaz\\OneDrive - IE University\\00. IE Courses\\01. 2025_H2\\1. ML4HC\\ICU_Survival_analysis\\wandb\\run-20251022_205404-0n6jhacv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/0n6jhacv' target=\"_blank\">eager-thunder-9</a></strong> to <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/0n6jhacv' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/0n6jhacv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen thresholds -> Sensitivity target: 0.321, Specificity target: 0.226\n",
      "Test metrics at sensitivity target: {'threshold': 0.321223955496573, 'sensitivity': 0.9009009009009009, 'specificity': 0.9564586357039188, 'ppv': 0.7692307692307693, 'npv': 0.9835820895522388, 'prevalence': 0.13875}\n",
      "Test metrics at specificity target: {'threshold': 0.2263541808615648, 'sensitivity': 1.0, 'specificity': 0.8969521044992743, 'ppv': 0.6098901098901099, 'npv': 1.0, 'prevalence': 0.13875}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-thunder-9</strong> at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/0n6jhacv' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/0n6jhacv</a><br> View project at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a><br>Synced 5 W&B file(s), 4 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251022_205404-0n6jhacv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8. Threshold selection for the current Random Forest baseline\n",
    "\n",
    "# Compute probabilities from the already-fitted Random Forest\n",
    "y_val_prob = rf.predict_proba(X_val_t)[:, 1]\n",
    "y_test_prob = rf.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "\n",
    "run = wandb.init(\n",
    "    project=WB_PROJECT,\n",
    "    job_type=\"threshold_selection\",\n",
    "    config={\n",
    "        \"model_type\": \"random_forest\",\n",
    "        \"seed\": SEED,\n",
    "        \"target_sensitivity\": 0.85,   # to be adjusted and defined per clinical use case\n",
    "        \"target_specificity\": 0.90    # to be adjusted and defined per clinical use case\n",
    "    },\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"thread\")\n",
    ")\n",
    "\n",
    "# Helper: compute metrics at a given threshold\n",
    "def metrics_at_threshold(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else np.nan   # recall for positives\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else np.nan   # recall for negatives\n",
    "    ppv = tp / (tp + fp) if (tp + fp) > 0 else np.nan           # precision\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else np.nan\n",
    "    prevalence = (tp + fn) / (tp + tn + fp + fn)\n",
    "    return dict(\n",
    "        threshold=float(thr),\n",
    "        tp=int(tp), fp=int(fp), tn=int(tn), fn=int(fn),\n",
    "        sensitivity=float(sensitivity),\n",
    "        specificity=float(specificity),\n",
    "        ppv=float(ppv), npv=float(npv),\n",
    "        prevalence=float(prevalence)\n",
    "    )\n",
    "\n",
    "# Sweep a dense grid of thresholds on Validation\n",
    "grid = np.unique(np.quantile(y_val_prob, q=np.linspace(0, 1, 501)))  # 0.2 percent steps by quantiles\n",
    "\n",
    "val_rows = [metrics_at_threshold(y_val, y_val_prob, thr) for thr in grid]\n",
    "val_tbl = pd.DataFrame(val_rows)\n",
    "\n",
    "# Pick thresholds closest to targets on Validation\n",
    "t_sens = run.config[\"target_sensitivity\"]\n",
    "t_spec = run.config[\"target_specificity\"]\n",
    "\n",
    "thr_for_sens = val_tbl.iloc[(val_tbl[\"sensitivity\"] - t_sens).abs().argsort()].iloc[0][\"threshold\"]\n",
    "thr_for_spec = val_tbl.iloc[(val_tbl[\"specificity\"] - t_spec).abs().argsort()].iloc[0][\"threshold\"]\n",
    "\n",
    "# Log chosen thresholds\n",
    "wandb.config.update({\n",
    "    \"chosen_threshold_sensitivity\": float(thr_for_sens),\n",
    "    \"chosen_threshold_specificity\": float(thr_for_spec)\n",
    "}, allow_val_change=True)\n",
    "\n",
    "# Apply frozen thresholds on Test\n",
    "test_at_sens = metrics_at_threshold(y_test, y_test_prob, thr_for_sens)\n",
    "test_at_spec = metrics_at_threshold(y_test, y_test_prob, thr_for_spec)\n",
    "\n",
    "# Build W&B Tables\n",
    "val_table_wb = wandb.Table(dataframe=val_tbl[[\"threshold\",\"sensitivity\",\"specificity\",\"ppv\",\"npv\",\"prevalence\"]])\n",
    "wandb.log({\"validation_threshold_sweep\": val_table_wb})\n",
    "\n",
    "test_results_tbl = pd.DataFrame([\n",
    "    dict(target=\"sensitivity\", **test_at_sens),\n",
    "    dict(target=\"specificity\", **test_at_spec)\n",
    "])\n",
    "\n",
    "wandb.log({\n",
    "    \"test_operating_points\": wandb.Table(dataframe=test_results_tbl[[\n",
    "        \"target\",\"threshold\",\"tp\",\"fp\",\"tn\",\"fn\",\"sensitivity\",\"specificity\",\"ppv\",\"npv\",\"prevalence\"\n",
    "    ]])\n",
    "})\n",
    "\n",
    "# Also log the two confusion matrices as compact tables\n",
    "def cm_table(row):\n",
    "    return wandb.Table(data=[\n",
    "        [\"Actual 0\", row[\"tn\"], row[\"fp\"]],\n",
    "        [\"Actual 1\", row[\"fn\"], row[\"tp\"]],\n",
    "    ], columns=[\"\", \"Pred 0\", \"Pred 1\"])\n",
    "\n",
    "wandb.log({\n",
    "    \"confusion_matrix_test_at_sensitivity\": cm_table(test_at_sens),\n",
    "    \"confusion_matrix_test_at_specificity\": cm_table(test_at_spec)\n",
    "})\n",
    "\n",
    "print(f\"Chosen thresholds -> Sensitivity target: {thr_for_sens:.3f}, Specificity target: {thr_for_spec:.3f}\")\n",
    "print(\"Test metrics at sensitivity target:\", {k: v for k, v in test_at_sens.items() if k not in [\"tp\",\"fp\",\"tn\",\"fn\"]})\n",
    "print(\"Test metrics at specificity target:\", {k: v for k, v in test_at_spec.items() if k not in [\"tp\",\"fp\",\"tn\",\"fn\"]})\n",
    "\n",
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e07314",
   "metadata": {},
   "source": [
    "# 9. Subgroup performance\n",
    "\n",
    "We'll evaluate the Random Forest on clinically relevant subgroups to check consistency of performance\n",
    "Subgroups (as identified during our CPH analysis):\n",
    "- **SOFA** score (severity of illness)\n",
    "- **CSRU** (Cardiac Surgery Recovery Unit)\n",
    "\n",
    "These two variables were the most significant predictors of mortality in the Cox Proportional Hazards analysis.  \n",
    "We will use the thresholds chosen on Validation and report metrics on Test in Weights & Biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c772353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\idiaz\\OneDrive - IE University\\00. IE Courses\\01. 2025_H2\\1. ML4HC\\ICU_Survival_analysis\\wandb\\run-20251022_210832-lvyjluqh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/lvyjluqh' target=\"_blank\">deep-glitter-10</a></strong> to <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/lvyjluqh' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/lvyjluqh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged subgroup metrics for SOFA bins and CSRU vs non-CSRU on Test\n"
     ]
    }
   ],
   "source": [
    "# Subgroup performance on Test using SOFA bands and CSRU flag\n",
    "# Uses thresholds thr_for_sens and thr_for_spec chosen in the previous step\n",
    "\n",
    "\n",
    "run = wandb.init(\n",
    "    project=WB_PROJECT,\n",
    "    job_type=\"subgroup_eval\",\n",
    "    config={\n",
    "        \"model_type\": \"random_forest\",\n",
    "        \"seed\": SEED,\n",
    "        \"subgroups\": [\"SOFA_bin\", \"CSRU\"]\n",
    "    },\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"thread\")\n",
    ")\n",
    "\n",
    "# Define subgroup columns\n",
    "SOFA_COL = \"SOFA\"\n",
    "CSRU_COL = \"CSRU\"\n",
    "\n",
    "# Extract subgroups from Test set\n",
    "test_idx = X_test.index\n",
    "sofa_test = ICU.loc[test_idx, SOFA_COL]\n",
    "csru_test = ICU.loc[test_idx, CSRU_COL]\n",
    "\n",
    "# Create SOFA quantile bins (5 bands by severity)\n",
    "sofa_bins = pd.qcut(sofa_test, q=5, duplicates=\"drop\").astype(str)\n",
    "\n",
    "# Binary label for CSRU membership\n",
    "csru_group = np.where(pd.to_numeric(csru_test, errors=\"coerce\").fillna(0).astype(int) == 1, \"CSRU\", \"non_CSRU\")\n",
    "\n",
    "# Helper to compute metrics at fixed threshold\n",
    "def metrics_fixed_threshold(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    sens = tp / (tp + fn) if (tp + fn) else np.nan\n",
    "    spec = tn / (tn + fp) if (tn + fp) else np.nan\n",
    "    ppv  = tp / (tp + fp) if (tp + fp) else np.nan\n",
    "    npv  = tn / (tn + fn) if (tn + fn) else np.nan\n",
    "    prev = (tp + fn) / (tp + tn + fp + fn)\n",
    "    return dict(\n",
    "        tp=int(tp), fp=int(fp), tn=int(tn), fn=int(fn),\n",
    "        sensitivity=float(sens), specificity=float(spec),\n",
    "        ppv=float(ppv), npv=float(npv), prevalence=float(prev)\n",
    "    )\n",
    "\n",
    "# Aggregate metrics per subgroup\n",
    "rows = []\n",
    "\n",
    "def add_group(group_name, group_values):\n",
    "    series = pd.Series(group_values, index=test_idx).astype(str)\n",
    "    for g in sorted(series.unique()):\n",
    "        mask = (series == g).values\n",
    "        y_true_g = y_test.values[mask]\n",
    "        y_prob_g = y_test_prob[mask]\n",
    "        if len(y_true_g) < 10:\n",
    "            continue\n",
    "        auroc = roc_auc_score(y_true_g, y_prob_g)\n",
    "        auprc = average_precision_score(y_true_g, y_prob_g)\n",
    "        m_sens = metrics_fixed_threshold(y_true_g, y_prob_g, thr_for_sens)\n",
    "        m_spec = metrics_fixed_threshold(y_true_g, y_prob_g, thr_for_spec)\n",
    "        rows.append({\n",
    "            \"model_type\": \"random_forest\",\n",
    "            \"subgroup_type\": group_name,\n",
    "            \"subgroup_value\": g,\n",
    "            \"n\": int(len(y_true_g)),\n",
    "            \"auroc\": float(auroc),\n",
    "            \"auprc\": float(auprc),\n",
    "            \"target\": \"sensitivity\",\n",
    "            \"threshold\": float(thr_for_sens),\n",
    "            **m_sens\n",
    "        })\n",
    "        rows.append({\n",
    "            \"model_type\": \"random_forest\",\n",
    "            \"subgroup_type\": group_name,\n",
    "            \"subgroup_value\": g,\n",
    "            \"n\": int(len(y_true_g)),\n",
    "            \"auroc\": float(auroc),\n",
    "            \"auprc\": float(auprc),\n",
    "            \"target\": \"specificity\",\n",
    "            \"threshold\": float(thr_for_spec),\n",
    "            **m_spec\n",
    "        })\n",
    "\n",
    "# Add SOFA and CSRU subgroups\n",
    "add_group(\"SOFA_bin\", sofa_bins)\n",
    "add_group(\"ICU_unit\", csru_group)\n",
    "\n",
    "subgroup_df = pd.DataFrame(rows)\n",
    "\n",
    "wandb.log({\n",
    "    \"subgroup_metrics_test\": wandb.Table(dataframe=subgroup_df[[\n",
    "        \"model_type\",\"subgroup_type\",\"subgroup_value\",\"n\",\n",
    "        \"target\",\"threshold\",\n",
    "        \"auroc\",\"auprc\",\"sensitivity\",\"specificity\",\"ppv\",\"npv\",\"prevalence\",\n",
    "        \"tp\",\"fp\",\"tn\",\"fn\"\n",
    "    ]]),\n",
    "    \"subgroup_columns_used\": wandb.Table(data=[[SOFA_COL, CSRU_COL]], columns=[\"sofa_column\",\"icu_unit_column\"])\n",
    "})\n",
    "\n",
    "print(\"Logged subgroup metrics for SOFA bins and CSRU vs non-CSRU on Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2861bb",
   "metadata": {},
   "source": [
    "### To Do\n",
    "\n",
    "- In the Weights & Biases table, compare SOFA bins and CSRU vs non CSRU\n",
    "- Look for drops in sensitivity or PPV at the chosen threshold\n",
    "- If performance varies widely by subgroup, discuss mitigation options such as recalibration or separate thresholds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195184a",
   "metadata": {},
   "source": [
    "# 10. Interpretability for understanding\n",
    "\n",
    "Model interpretability connects predictive performance to clinical meaning:\n",
    "- Use **Permutation Importance** for Logistic Regression, Decision Tree, and Random Forest  \n",
    "- Use **SHAP** on the Random Forest to see which features drive individual predictions  \n",
    "\n",
    "All outputs are logged to Weights & Biases for exploration and comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a501df48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-smoke-14</strong> at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/a3g8af8b' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/a3g8af8b</a><br> View project at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a><br>Synced 5 W&B file(s), 3 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251022_213033-a3g8af8b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\idiaz\\OneDrive - IE University\\00. IE Courses\\01. 2025_H2\\1. ML4HC\\ICU_Survival_analysis\\wandb\\run-20251022_213328-apjrien3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/apjrien3' target=\"_blank\">winter-blaze-15</a></strong> to <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/apjrien3' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/apjrien3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idiaz\\AppData\\Local\\Temp\\ipykernel_19324\\149745412.py:75: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, shap_sample, show=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">winter-blaze-15</strong> at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro/runs/apjrien3' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro/runs/apjrien3</a><br> View project at: <a href='https://wandb.ai/idiazl/ml-healthcare-intro' target=\"_blank\">https://wandb.ai/idiazl/ml-healthcare-intro</a><br>Synced 5 W&B file(s), 5 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251022_213328-apjrien3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interpretability: Permutation Importance and SHAP for Random Forest\n",
    "# Logs all interpretability outputs to W&B\n",
    "\n",
    "run = wandb.init(\n",
    "    project=WB_PROJECT,\n",
    "    job_type=\"interpretability\",\n",
    "    config={\n",
    "        \"models\": [\"logistic_regression\", \"decision_tree\", \"random_forest\"],\n",
    "        \"shap_sample_size\": 500\n",
    "    },\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"thread\")\n",
    ")\n",
    "\n",
    "# 1) Permutation Importance for all models on Validation\n",
    "models = {\n",
    "    \"logistic_regression\": log_reg,\n",
    "    \"decision_tree\": dt,\n",
    "    \"random_forest\": rf\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    result = permutation_importance(\n",
    "        model, X_val_t, y_val, n_repeats=10, random_state=SEED, n_jobs=-1\n",
    "    )\n",
    "    imp_df = (\n",
    "        pd.DataFrame({\n",
    "            \"feature\": X_val_t.columns,\n",
    "            \"importance_mean\": result.importances_mean,\n",
    "            \"importance_std\": result.importances_std\n",
    "        })\n",
    "        .sort_values(\"importance_mean\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    wandb.log({f\"{model_name}_permutation_importance\": wandb.Table(dataframe=imp_df)})\n",
    "\n",
    "# 2) SHAP for Random Forest on a small Validation sample\n",
    "# Use model_output=\"raw\" for tree_path_dependent\n",
    "# Log summary plot image and a ranked table of mean |SHAP| values\n",
    "\n",
    "\n",
    "# Sample a manageable slice from Validation\n",
    "shap_sample_n = min(500, len(X_val_t))\n",
    "shap_sample = X_val_t.sample(n=shap_sample_n, random_state=SEED)\n",
    "\n",
    "# Use raw output with tree_path_dependent for tree models\n",
    "explainer = shap.TreeExplainer(\n",
    "    rf,\n",
    "    model_output=\"raw\",\n",
    "    feature_perturbation=\"tree_path_dependent\"\n",
    ")\n",
    "\n",
    "# Avoid additivity mismatches across sklearn versions\n",
    "shap_values_raw = explainer.shap_values(shap_sample, check_additivity=False)\n",
    "\n",
    "# Select SHAP values for the positive class and ensure 2D shape (n_samples, n_features)\n",
    "if isinstance(shap_values_raw, list):\n",
    "    sv = np.asarray(shap_values_raw[1])  # class 1\n",
    "else:\n",
    "    sv = np.asarray(shap_values_raw)\n",
    "\n",
    "# If 3D, last axis usually indexes classes\n",
    "if sv.ndim == 3:\n",
    "    # prefer class 1 if available, else class 0\n",
    "    cls_axis = sv.shape[-1]\n",
    "    pick = 1 if cls_axis >= 2 else 0\n",
    "    sv = sv[..., pick]\n",
    "\n",
    "# Safety: squeeze any trailing singleton dims\n",
    "sv = np.squeeze(sv)\n",
    "assert sv.ndim == 2, f\"Expected 2D SHAP values after selection, got {sv.shape}\"\n",
    "assert sv.shape[1] == shap_sample.shape[1], \"Feature count mismatch between SHAP and input data\"\n",
    "\n",
    "# Global summary plot\n",
    "shap.summary_plot(sv, shap_sample, show=False)\n",
    "wandb.log({\"shap_summary_plot\": wandb.Image(plt.gcf())})\n",
    "plt.close()\n",
    "\n",
    "# Ranked mean absolute SHAP for table\n",
    "mean_abs_shap = np.abs(sv).mean(axis=0).reshape(-1)\n",
    "feat_names = list(shap_sample.columns)\n",
    "\n",
    "shap_df = pd.DataFrame(\n",
    "    {\"feature\": feat_names, \"mean_abs_shap\": mean_abs_shap}\n",
    ").sort_values(\"mean_abs_shap\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "wandb.log({\"rf_shap_feature_importance\": wandb.Table(dataframe=shap_df)})\n",
    "\n",
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4cf119",
   "metadata": {},
   "source": [
    "### To DO\n",
    "In Weights & Biases:\n",
    "- Use the permutation importance tables to see which features most influence predictions  \n",
    "- Compare across models to note stability of top features  \n",
    "- In the SHAP summary, focus on high impact variables — for instance, rising SOFA and CSRU membership should drive higher predicted mortality  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d902532",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icu-survival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
